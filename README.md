# Real-Time-Moroccan-Sign-Language-Translator
# Real-Time-Moroccan-Sign-Language-Translator
<!-- ############################################################### -->
<!-- #               README.md dyal projet professional            # -->
<!-- # Copier-coller hadchi kaml f fichier README.md dyalk          # -->
<!-- # W bdel l'hajat li bin had les commentaires                 # -->
<!-- ############################################################### -->

# üá≤üá¶ Traducteur de Langue des Signes Marocaine (LSM) en Temps R√©el

<!-- BDEL HAD LES BADGES B SMIYA DYAL L'REPO W L'USERNAME DYALK F GITHUB -->
![Python](https://img.shields.io/badge/Python-3.9-blue.svg?style=for-the-badge&logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)

<!-- L'KHOTWA L'MOHIMA BZAF: Mli tssali l'projet, sn3 GIF zwin dyal l'application khdama
     b ScreenToGif (f Windows) wlla Giphy Capture (f Mac), w 7eto f l'dossier dyal l'projet.
     Bdel "demo.gif" ltaht b smiya dyal l'fichier dyalk. Hada howa li ghaybiyen 9owa dyal l'projet. -->
<p align="center">
  <img src="demo.gif" alt="D√©monstration de l'application" width="700"/> <br>
  <img src="demo2.gif" alt="D√©monstration de l'application" width="700"/>   
</p>

Ce projet est une application d'Intelligence Artificielle capable de reconna√Ætre et de traduire la **Langue des Signes Marocaine (LSM)** en texte, en temps r√©el, en utilisant la cam√©ra d'un ordinateur. L'objectif est de faciliter la communication entre la communaut√© des sourds et muets et le grand public.

_This project is an AI-powered application that recognizes and translates **Moroccan Sign Language (MSL)** into text in real-time, using a standard computer camera. The goal is to bridge the communication gap between the deaf and mute community and the general public._

---

## ‚ú® Fonctionnalit√©s / Features

*   **Traduction en Temps R√©el :** Analyse le flux vid√©o de la cam√©ra et affiche la traduction instantan√©ment.
*   **Haute Pr√©cision :** Utilise un mod√®le de Deep Learning moderne (CNN + LSTM) pour une reconnaissance robuste des gestes.
*   **Architecture Modulaire :** Le code est organis√© de mani√®re professionnelle, s√©parant la pr√©paration des donn√©es, l'entra√Ænement et l'inf√©rence.
*   **Interface Intuitive :** Une interface utilisateur simple construite avec Streamlit pour une utilisation facile.
*   **Extensible :** Con√ßu pour pouvoir ajouter facilement de nouveaux gestes et mots au vocabulaire.

---

## üõ†Ô∏è Stack Technique / Built With

Ce projet a √©t√© r√©alis√© en utilisant les technologies suivantes :

*   **Framework IA :** [PyTorch](https://pytorch.org/)
*   **Vision par Ordinateur :** [OpenCV](https://opencv.org/), [MediaPipe](https://google.github.io/mediapipe/)
*   **Interface Utilisateur :** [Streamlit](https://streamlit.io/)
*   **Manipulation de Donn√©es :** [NumPy](https://numpy.org/)
*   **Analyse de Performance :** [Scikit-learn](https://scikit-learn.org/), [Matplotlib](https://matplotlib.org/)

---

## üöÄ D√©marrage / Getting Started

Suivez ces √©tapes pour installer et lancer le projet sur votre machine.

### Pr√©requis / Prerequisites

*   Avoir [Git](https://git-scm.com/) install√©.
*   Avoir [Miniconda](https://docs.conda.io/en/latest/miniconda.html) ou Anaconda install√©.
*   Un dataset de vid√©os de la LSM, organis√© en sous-dossiers par mot (ex: `.../clavier/video1.mp4`).

### Installation & Configuration

1.  **Cloner le repository GitHub :**
    ```bash
    git clone https://github.com/votre-username/votre-repo-name.git
    cd votre-repo-name
    ```
    <!-- BDEL 'votre-username' w 'votre-repo-name' -->

2.  **Cr√©er un environnement Conda :**
    ```bash
    conda create --name lsm_env python=3.9
    conda activate lsm_env
    ```

3.  **Installer les d√©pendances :**
    ```bash
    pip install torch torchvision torchaudio
    pip install -r requirements.txt
    ```
    _Note : Vous devez d'abord cr√©er un fichier `requirements.txt` contenant les autres d√©pendances comme `opencv-python`, `mediapipe`, `streamlit`, etc._

---

## üìñ Utilisation / Usage

Le projet est divis√© en 3 √©tapes principales.

### 1. Pr√©paration des Donn√©es

Placez vos vid√©os dans le dossier `data/raw_videos/`, organis√©es par geste. Ensuite, ex√©cutez les scripts de pr√©-traitement.

```bash
# Choisir votre environnement (local/cloud) dans les scripts d'abord
python src/01_preprocess.py
python src/02_normalize.py
